{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Model Training\n",
    "*Note: If you are prompted to select a kernel, please select SageMaker Jumpstart PyTorch 1.0*\n",
    "\n",
    "In this notebook we will train a model on our sample data set to detect failures.\n",
    "\n",
    "You can select Run->Run All Cells from the menu to run all cells in Studio (or Cell->Run All in a SageMaker Notebook Instance)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import boto3\n",
    "import sagemaker\n",
    "import numpy as np\n",
    "\n",
    "from sagemaker.pytorch import PyTorch\n",
    "from sagemaker.s3 import S3Uploader\n",
    "from sagemaker.tuner import IntegerParameter, CategoricalParameter, ContinuousParameter, HyperparameterTuner\n",
    "\n",
    "from source.config import Config\n",
    "config = Config(filename=\"config/config.yaml\")\n",
    "\n",
    "with open(\"stack_outputs.json\") as f:\n",
    "    sagemaker_configs = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "## Training Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sage_session = sagemaker.session.Session()\n",
    "s3_bucket = sagemaker_configs[\"S3Bucket\"]  \n",
    "s3_output_path = 's3://{}/'.format(s3_bucket)\n",
    "print(\"S3 bucket path: {}\".format(s3_output_path))\n",
    "\n",
    "# run in local_mode on this machine, or as a SageMaker TrainingJob\n",
    "local_mode = False\n",
    "\n",
    "if local_mode:\n",
    "    instance_type = 'local'\n",
    "else:\n",
    "    instance_type = sagemaker_configs[\"SageMakerTrainingInstanceType\"]\n",
    "    \n",
    "role = sagemaker_configs['SageMakerIamRole']\n",
    "print(\"Using IAM role arn: {}\".format(role))\n",
    "# only run from SageMaker notebook instance\n",
    "if local_mode:\n",
    "    !/bin/bash ./setup.sh\n",
    "cpu_or_gpu = 'gpu' if instance_type.startswith('ml.p') else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a descriptive job name \n",
    "job_name_prefix = 'sagemaker-soln-fpm'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_definitions = [\n",
    "    {'Name': 'Epoch', 'Regex': 'Epoch: ([-+]?[0-9]*[.]?[0-9]+([eE][-+]?[0-9]+)?)'},\n",
    "    {'Name': 'train_loss', 'Regex': 'Train loss: ([-+]?[0-9]*[.]?[0-9]+([eE][-+]?[0-9]+)?)'},\n",
    "    {'Name': 'train_acc',  'Regex': 'Train acc: ([-+]?[0-9]*[.]?[0-9]+([eE][-+]?[0-9]+)?)'},\n",
    "    {'Name': 'train_auc',  'Regex': 'Train auc: ([-+]?[0-9]*[.]?[0-9]+([eE][-+]?[0-9]+)?)'},\n",
    "    {'Name': 'test_loss', 'Regex': 'Test loss: ([-+]?[0-9]*[.]?[0-9]+([eE][-+]?[0-9]+)?)'},\n",
    "    {'Name': 'test_acc', 'Regex': 'Test acc: ([-+]?[0-9]*[.]?[0-9]+([eE][-+]?[0-9]+)?)'},\n",
    "    {'Name': 'test_auc', 'Regex': 'Test auc: ([-+]?[0-9]*[.]?[0-9]+([eE][-+]?[0-9]+)?)'},\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define your data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Using dataset {}\".format(config.train_dataset_fn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "key_prefix='fpm-data'\n",
    "training_data = S3Uploader.upload(config.train_dataset_fn, 's3://{}/{}'.format(s3_bucket, key_prefix))\n",
    "testing_data = S3Uploader.upload(config.test_dataset_fn, 's3://{}/{}'.format(s3_bucket, key_prefix))\n",
    "\n",
    "print(\"Training data: {}\".format(training_data))\n",
    "print(\"Testing data: {}\".format(testing_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Optimization\n",
    "We will use SageMaker Hyperparameter Tuning to choose the best hyperparameters for the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_jobs = 4\n",
    "max_parallel_jobs = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameter_ranges = {\n",
    "    'lr': ContinuousParameter(1e-5, 1e-2),\n",
    "    'batch_size': IntegerParameter(16, 256),\n",
    "    'dropout': ContinuousParameter(0.0, 0.8),\n",
    "    \n",
    "    'fc_hidden_units': CategoricalParameter([\"[256, 128]\", \"[256, 128, 128]\", \"[256, 256, 128]\", \"[256, 128, 64]\"]),\n",
    "    'conv_channels': CategoricalParameter([\"[2, 8, 2]\", \"[2, 16, 2]\", \"[2, 16, 16, 2]\"]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "estimator = PyTorch(entry_point=\"train.py\",\n",
    "                    source_dir='source',                    \n",
    "                    role=role,\n",
    "                    dependencies=[\"source/dl_utils\"],\n",
    "                    train_instance_type=instance_type,\n",
    "                    train_instance_count=1,\n",
    "                    output_path=s3_output_path,\n",
    "                    framework_version=\"1.5.0\",\n",
    "                    py_version='py3',\n",
    "                    base_job_name=job_name_prefix,\n",
    "                    metric_definitions=metric_definitions,\n",
    "                    hyperparameters= {\n",
    "                        'epoch': 5000,\n",
    "                        'target_column': config.target_column,\n",
    "                        'sensor_headers': json.dumps(config.sensor_headers),\n",
    "                        'train_input_filename': os.path.basename(config.train_dataset_fn),\n",
    "                        'test_input_filename': os.path.basename(config.test_dataset_fn),\n",
    "                        }\n",
    "                     )\n",
    "\n",
    "if local_mode:\n",
    "    estimator.fit({'train': training_data, 'test': testing_data})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = HyperparameterTuner(estimator,\n",
    "                            objective_metric_name='test_auc',\n",
    "                            objective_type='Maximize',\n",
    "                            hyperparameter_ranges=hyperparameter_ranges,\n",
    "                            metric_definitions=metric_definitions,\n",
    "                            max_jobs=max_jobs,\n",
    "                            max_parallel_jobs=max_parallel_jobs,\n",
    "                            base_tuning_job_name=job_name_prefix)\n",
    "tuner.fit({'train': training_data, 'test': testing_data})\n",
    "tuner.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Please note that the hyperparameter tuning job takes 3 to 4 hours to complete."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Stage\n",
    "Up next we will analyze the results. [Click here to continue](./5_results_analysis.ipynb)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (PyTorch JumpStart)",
   "language": "python",
   "name": "HUB_1P_IMAGE"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}